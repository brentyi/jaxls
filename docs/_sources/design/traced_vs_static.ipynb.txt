{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, format=\"<level>{level: <8}</level> | {message}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# What's traced?\n",
    "\n",
    "JAX's JIT compilation requires distinguishing between traced values (that can\n",
    "change between calls) and static values (that trigger recompilation if changed).\n",
    "\n",
    "This page discusses:\n",
    "- What's traced vs static in jaxls\n",
    "- Why variable IDs are traced\n",
    "- What triggers recompilation\n",
    "- Examples: leveraging traced values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Background: JAX tracing\n",
    "\n",
    "When JAX JIT-compiles a function, it traces the computation with abstract values.\n",
    "Values can be:\n",
    "\n",
    "- Traced: Represented as abstract shapes/dtypes during compilation. The actual\n",
    "  values are substituted at runtime. Changing traced values doesn't trigger recompilation.\n",
    "\n",
    "- Static: Baked into the compiled code. Changing static values triggers a new\n",
    "  compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## jaxls's static/traced split\n",
    "\n",
    "### Traced (can change without recompilation)\n",
    "\n",
    "| Value | Why traced |\n",
    "|-------|------------|\n",
    "| Variable IDs (`Var.id`) | Different variable subsets use same code |\n",
    "| Variable values (`VarValues`) | Values change during optimization |\n",
    "| Jacobian values | Computed from current variable values |\n",
    "| Solver parameters (LM damping, CG tolerance) | May adapt during solve |\n",
    "| Augmented Lagrangian multipliers/penalties | Updated between outer iterations |\n",
    "\n",
    "### Static (changes trigger recompilation)\n",
    "\n",
    "| Value | Why static |\n",
    "|-------|------------|\n",
    "| Problem dimensions (`_tangent_dim`, `_residual_dim`) | Affects array shapes |\n",
    "| Cost counts and structure (`_cost_counts`) | Affects loop bounds |\n",
    "| Solver choice (`linear_solver`, `sparse_mode`) | Different code paths |\n",
    "| Variable tangent dimensions | Affects Jacobian block sizes |\n",
    "| Constraint types (equality vs inequality) | Affects AL update logic |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Why variable IDs are traced\n",
    "\n",
    "`Var.id` is a traced `jax.Array`, not a static `int`. This enables automatic\n",
    "vectorization of costs. These two approaches produce equivalent results after analysis:\n",
    "\n",
    "```python\n",
    "# Approach A: Array of IDs (explicitly batched).\n",
    "costs_a = [\n",
    "    pairwise_cost(\n",
    "        MyVar(id=jnp.arange(100)),      # IDs 0-99\n",
    "        MyVar(id=jnp.arange(100) + 1),  # IDs 1-100\n",
    "        data,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Approach B: List comprehension (implicitly batched).\n",
    "costs_b = [\n",
    "    pairwise_cost(MyVar(id=i), MyVar(id=i + 1), data[i])\n",
    "    for i in range(100)\n",
    "]\n",
    "```\n",
    "\n",
    "In approach A, the IDs are explicit arrays. In approach B, jaxls stacks the\n",
    "scalar IDs into arrays during `analyze()`. Either way, the analyzed problem\n",
    "vmaps over the ID arrays to compute residuals and Jacobians in parallel.\n",
    "\n",
    "This also works with inline lambda functions:\n",
    "\n",
    "```python\n",
    "# Approach C: Inline lambdas with list comprehension.\n",
    "costs_c = [\n",
    "    jaxls.Cost.factory(\n",
    "        lambda vals, v: vals[v] - target[i]\n",
    "    )(MyVar(id=i))\n",
    "    for i in range(100)\n",
    "]\n",
    "```\n",
    "\n",
    "Even though this creates 100 separate lambda objects, jaxls recognizes them as\n",
    "the same cost type using bytecode analysis: `dis.Bytecode` extracts the instruction\n",
    "sequence, which is identical across all 100 lambdas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Implementation: `jdc.Static`\n",
    "\n",
    "jaxls uses `jax_dataclasses` with the `jdc.Static[]` type annotation to mark static fields:\n",
    "\n",
    "```python\n",
    "@jdc.pytree_dataclass\n",
    "class AnalyzedLeastSquaresProblem:\n",
    "    # Traced fields (part of pytree).\n",
    "    _stacked_costs: tuple[_AnalyzedCost, ...]\n",
    "    _sorted_ids_from_var_type: dict[type[Var], jax.Array]\n",
    "    \n",
    "    # Static fields (not part of pytree, trigger recompile if changed).\n",
    "    _cost_counts: jdc.Static[tuple[int, ...]]\n",
    "    _tangent_dim: jdc.Static[int]\n",
    "    _residual_dim: jdc.Static[int]\n",
    "```\n",
    "\n",
    "Static fields are excluded from the pytree structure, so JAX treats them as\n",
    "compile-time constants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## What triggers recompilation?\n",
    "\n",
    "### Does not trigger recompilation\n",
    "\n",
    "- Different variable IDs (as long as count and types are the same)\n",
    "- Different variable values\n",
    "- Different initial guesses\n",
    "- Different solver parameters (trust region damping, CG tolerance)\n",
    "- Different AL penalty parameters\n",
    "\n",
    "### Triggers recompilation\n",
    "\n",
    "- Adding/removing variables or costs\n",
    "- Changing variable types\n",
    "- Changing problem dimensions\n",
    "- Switching linear solver (CG \u2192 Cholesky)\n",
    "- Changing sparse matrix mode\n",
    "\n",
    "The first solve is slower (includes compilation), but subsequent solves with\n",
    "the same structure are fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Examples: leveraging traced values\n",
    "\n",
    "### Different variable assignments\n",
    "\n",
    "The same cost structure can connect different variables without recompilation.\n",
    "{func}`jax.jit` will only compile the first call:\n",
    "\n",
    "```python\n",
    "@jax.jit\n",
    "def solve_with_ids(\n",
    "    var_ids: jax.Array,  # Which variables to use.\n",
    "    targets: jax.Array,\n",
    ") -> jaxls.VarValues:\n",
    "    # Same cost type, but connecting different variable IDs.\n",
    "    costs = [prior_cost(MyVar(id=var_ids), targets)]\n",
    "    problem = jaxls.LeastSquaresProblem(costs).analyze()\n",
    "    return problem.solve(initial_vals).vals\n",
    "\n",
    "# First call compiles; subsequent calls reuse compiled code.\n",
    "solution1 = solve_with_ids(jnp.array([0, 1, 2]), targets_a)\n",
    "solution2 = solve_with_ids(jnp.array([3, 4, 5]), targets_b)  # No recompilation.\n",
    "```\n",
    "\n",
    "### Batched solves with vmap\n",
    "\n",
    "With {func}`jax.vmap`, solve multiple problem instances in parallel by vmapping\n",
    "over initial values:\n",
    "\n",
    "```python\n",
    "def solve_one(init_vals: jaxls.VarValues) -> jaxls.VarValues:\n",
    "    return problem.solve(init_vals).vals\n",
    "\n",
    "# Solve 100 problems in parallel.\n",
    "batched_solutions = jax.jit(jax.vmap(solve_one))(batched_init_vals)\n",
    "```\n",
    "\n",
    "### Sequential solves with scan\n",
    "\n",
    "With {func}`jax.lax.scan`, solve a sequence of problems where each uses the\n",
    "previous solution as its initial guess:\n",
    "\n",
    "```python\n",
    "def solve_step(vals: jaxls.VarValues, target: jax.Array) -> tuple[jaxls.VarValues, jax.Array]:\n",
    "    costs = [prior_cost(MyVar(id=jnp.arange(n)), target)]\n",
    "    problem = jaxls.LeastSquaresProblem(costs).analyze()\n",
    "    new_vals = problem.solve(vals).vals\n",
    "    return new_vals, new_vals[MyVar(id=jnp.arange(n))]\n",
    "\n",
    "# Solve for each target in sequence, warm-starting from previous solution.\n",
    "final_vals, trajectory = jax.lax.scan(solve_step, initial_vals, targets_sequence)\n",
    "```\n",
    "\n",
    "### Sweeping solver parameters\n",
    "\n",
    "Traced values can be sweeped over in parallel with {func}`jax.vmap`:\n",
    "\n",
    "```python\n",
    "def solve_with_damping(damping: float) -> jaxls.VarValues:\n",
    "    return problem.solve(\n",
    "        initial_vals,\n",
    "        trust_region=jaxls.TrustRegionConfig(lambda_initial=damping),\n",
    "    ).vals\n",
    "\n",
    "# Sweep over damping values.\n",
    "solutions = jax.jit(jax.vmap(solve_with_damping))(jnp.logspace(-3, 3, 10))\n",
    "```\n",
    "\n",
    "## Related pages\n",
    "\n",
    "- {doc}`../guide/tips_and_gotchas`: Batched construction and performance tips\n",
    "- {doc}`sparse_matrices`: How Jacobian sparsity is exploited"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
