{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Manifold allocation\n\nThe {doc}`mean-variance notebook <mean_variance>` treats allocation as a classical constrained\noptimization problem: we minimize variance subject to budget constraints (weights sum to 1)\nand no short-selling (weights non-negative).\n\nAn alternative perspective: the set of valid allocations forms a *manifold* called the\nprobability simplex. By defining a custom `retract_fn`, we can optimize directly on this manifold\nwithout explicit constraints.\n\nFeatures used:\n- {class}`~jaxls.Var` with custom `retract_fn` and `tangent_dim` for manifold variables\n- Multiplicative retraction for smooth simplex optimization"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, format=\"<level>{level: <8}</level> | {message}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## The probability simplex\n",
    "\n",
    "The probability simplex $\\Delta^{n-1}$ is the set of valid portfolio allocations:\n",
    "\n",
    "$$\\Delta^{n-1} = \\{w \\in \\mathbb{R}^n : w_i \\geq 0, \\sum_i w_i = 1\\}$$\n",
    "\n",
    "This is an $(n-1)$-dimensional manifold embedded in $\\mathbb{R}^n$. The sum-to-one constraint\n",
    "removes one degree of freedom.\n",
    "\n",
    "To optimize on this manifold, we need a **retraction**: a function `retract(x, delta)` that maps\n",
    "a point $x$ on the manifold plus an update $\\delta$ back to a valid point on the manifold. A valid\n",
    "retraction must satisfy:\n",
    "\n",
    "1. **Identity at zero**: `retract(x, 0) = x`\n",
    "2. **Stays on manifold**: output always satisfies the manifold constraints\n",
    "3. **Smoothness**: the function should be differentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Simplex retraction\n",
    "\n",
    "Our retraction uses multiplicative updates, which are additive in log-space:\n",
    "1. Scale each weight: `weights * exp(delta)`\n",
    "2. Normalize: divide by sum to ensure sum-to-one\n",
    "\n",
    "This satisfies the retraction requirements:\n",
    "- **Identity at zero**: `exp(0) = 1`, so `retract(w, 0) = w / sum(w) = w`\n",
    "- **Stays on manifold**: normalization ensures sum-to-one; `exp()` ensures positivity\n",
    "- **Smoothness**: both `exp()` and division are smooth operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplex_retract(weights: jax.Array, delta: jax.Array) -> jax.Array:\n",
    "    \"\"\"Multiplicative update that keeps weights positive and summing to 1.\"\"\"\n",
    "    v = weights * jnp.exp(delta)\n",
    "    return v / jnp.sum(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0.5 0.3 0.2] (sum=1.0000)\n",
      "After adding delta: [ 0.6        -0.09999999  0.3       ]\n",
      "After retraction: [0.5669196  0.2063125  0.22676793] (sum=1.0000)\n",
      "All non-negative: True\n"
     ]
    }
   ],
   "source": [
    "# Verify the retraction works.\n",
    "test_weights = jnp.array([0.5, 0.3, 0.2])\n",
    "test_delta = jnp.array([0.1, -0.4, 0.1])  # Would make middle weight negative.\n",
    "\n",
    "result = simplex_retract(test_weights, test_delta)\n",
    "print(f\"Initial weights: {test_weights} (sum={float(jnp.sum(test_weights)):.4f})\")\n",
    "print(f\"After adding delta: {test_weights + test_delta}\")\n",
    "print(f\"After retraction: {result} (sum={float(jnp.sum(result)):.4f})\")\n",
    "print(f\"All non-negative: {bool(jnp.all(result >= 0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Simplex variable type\n",
    "\n",
    "Now we define a variable type that lives on the simplex. The `retract_fn` ensures all updates\n",
    "produce valid allocations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplexWeightsVar tangent_dim: 3\n"
     ]
    }
   ],
   "source": [
    "n_assets = 3\n",
    "\n",
    "\n",
    "class SimplexWeightsVar(\n",
    "    jaxls.Var[jax.Array],\n",
    "    default_factory=lambda: jnp.ones(n_assets) / n_assets,\n",
    "    retract_fn=simplex_retract,\n",
    "    tangent_dim=n_assets,  # Projection handles the constraint.\n",
    "):\n",
    "    \"\"\"Portfolio weights on the probability simplex.\"\"\"\n",
    "\n",
    "\n",
    "print(f\"SimplexWeightsVar tangent_dim: {SimplexWeightsVar.tangent_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Asset data\n",
    "\n",
    "We use the same historical stock data as the mean-variance notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected monthly returns:\n",
      "  IBM: +2.60%\n",
      "  WMT: +0.81%\n",
      "  SEHI: +7.37%\n"
     ]
    }
   ],
   "source": [
    "stock_names = [\"IBM\", \"WMT\", \"SEHI\"]\n",
    "\n",
    "# Monthly prices (13 months: Nov 2000 - Nov 2001).\n",
    "prices = jnp.array(\n",
    "    [\n",
    "        [93.043, 51.826, 1.063],\n",
    "        [84.585, 52.823, 0.938],\n",
    "        [111.453, 56.477, 1.0],\n",
    "        [99.525, 49.805, 0.938],\n",
    "        [95.819, 50.287, 1.438],\n",
    "        [114.708, 51.521, 1.7],\n",
    "        [111.515, 51.531, 2.54],\n",
    "        [113.211, 48.664, 2.39],\n",
    "        [104.942, 55.744, 3.12],\n",
    "        [99.827, 47.916, 2.98],\n",
    "        [91.607, 49.438, 1.9],\n",
    "        [107.937, 51.336, 1.75],\n",
    "        [115.59, 55.081, 1.8],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compute returns and covariance.\n",
    "returns = jnp.diff(prices, axis=0) / prices[:-1]\n",
    "expected_returns = jnp.mean(returns, axis=0)\n",
    "returns_centered = returns - expected_returns\n",
    "covariance = (returns_centered.T @ returns_centered) / (returns.shape[0] - 1)\n",
    "cov_chol = jnp.linalg.cholesky(covariance)\n",
    "\n",
    "print(\"Expected monthly returns:\")\n",
    "for name, r in zip(stock_names, expected_returns):\n",
    "    print(f\"  {name}: {float(r) * 100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Problem formulation\n",
    "\n",
    "With the simplex variable, we only need a variance cost and a return constraint.\n",
    "The budget and no short-selling constraints are handled implicitly by the manifold geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_var = SimplexWeightsVar(id=0)\n",
    "\n",
    "\n",
    "@jaxls.Cost.factory\n",
    "def variance_cost(\n",
    "    vals: jaxls.VarValues, var: SimplexWeightsVar, cov_chol: jax.Array\n",
    ") -> jax.Array:\n",
    "    \"\"\"Minimize portfolio variance: ||L.T @ w||^2 = w.T @ cov @ w.\"\"\"\n",
    "    return cov_chol.T @ vals[var]\n",
    "\n",
    "\n",
    "@jaxls.Cost.factory(kind=\"constraint_geq_zero\")\n",
    "def return_constraint(\n",
    "    vals: jaxls.VarValues, var: SimplexWeightsVar, exp_ret: jax.Array, target: float\n",
    ") -> jax.Array:\n",
    "    \"\"\"Expected return must meet target: E[r] >= target.\"\"\"\n",
    "    return jnp.array([jnp.dot(vals[var], exp_ret) - target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Efficient frontier\n",
    "\n",
    "We compute the efficient frontier by solving for different target returns.\n",
    "Note that we only have one constraint (return target) instead of three.\n",
    "\n",
    "Using `jax.lax.scan`, we solve sequentially while using each solution as the\n",
    "initial guess for the next (warm-starting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_return = float(expected_returns.min())\n",
    "max_return = float(expected_returns.max())\n",
    "target_returns = jnp.linspace(min_return, max_return, 50)\n",
    "\n",
    "\n",
    "def solve_for_target(\n",
    "    current_vals: jaxls.VarValues, target: jax.Array\n",
    ") -> tuple[jaxls.VarValues, jax.Array]:\n",
    "    \"\"\"Solve portfolio optimization for a given target return.\n",
    "\n",
    "    Args:\n",
    "        current_vals: Solution from previous target (used as initial guess).\n",
    "        target: Target return for this solve.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (solution values, optimal weights).\n",
    "    \"\"\"\n",
    "    costs = [\n",
    "        variance_cost(weights_var, cov_chol),\n",
    "        return_constraint(weights_var, expected_returns, target),\n",
    "    ]\n",
    "    problem = jaxls.LeastSquaresProblem(costs, [weights_var]).analyze()\n",
    "    solution = problem.solve(\n",
    "        current_vals,\n",
    "        verbose=False,\n",
    "        linear_solver=\"dense_cholesky\",\n",
    "        termination=jaxls.TerminationConfig(cost_tolerance=1e-8),\n",
    "    )\n",
    "    return solution, solution[weights_var]\n",
    "\n",
    "\n",
    "# Solve sequentially with warm-starting.\n",
    "initial_vals = jaxls.VarValues.make([weights_var])\n",
    "_, all_weights = jax.lax.scan(solve_for_target, initial_vals, target_returns)\n",
    "variances = jax.vmap(lambda w: w @ covariance @ w)(all_weights)\n",
    "returns_achieved = jax.vmap(lambda w: jnp.dot(w, expected_returns))(all_weights)\n",
    "\n",
    "print(f\"Computed {len(target_returns)} points on the efficient frontier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight sums: min=1.000000, max=1.000000\n",
      "Min weight across all solutions: 0.000001\n",
      "All constraints satisfied by construction!\n"
     ]
    }
   ],
   "source": [
    "# Verify all solutions satisfy simplex constraints.\n",
    "weight_sums = jnp.sum(all_weights, axis=1)\n",
    "min_weights = jnp.min(all_weights, axis=1)\n",
    "\n",
    "print(\n",
    "    f\"Weight sums: min={float(weight_sums.min()):.6f}, max={float(weight_sums.max()):.6f}\"\n",
    ")\n",
    "print(f\"Min weight across all solutions: {float(min_weights.min()):.6f}\")\n",
    "print(\"All constraints satisfied by construction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": "import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom IPython.display import HTML\nimport math\n\n# Annualize returns and risk.\nannual_factor = 12\nrisk_free_rate = 0.05  # 5% annual risk-free rate.\n\nstd_devs_annual = [float(jnp.sqrt(v)) * math.sqrt(annual_factor) for v in variances]\nreturns_annual = [float(r) * annual_factor for r in returns_achieved]\nsharpe_ratios = [\n    (r - risk_free_rate) / s if s > 0 else 0.0\n    for r, s in zip(returns_annual, std_devs_annual)\n]\n\ncolors = [\"#2196F3\", \"#4CAF50\", \"#FF9800\"]\n\nfig = make_subplots(\n    rows=1,\n    cols=3,\n    subplot_titles=(\"Efficient Frontier\", \"Sharpe Ratio\", \"Asset Allocation\"),\n    column_widths=[0.33, 0.33, 0.34],\n)\n\n# Scale to $1000 investment.\nstd_dev_dollars = [s * 1000 for s in std_devs_annual]\nreturn_dollars = [r * 1000 for r in returns_annual]\ntarget_dollars = [float(t) * annual_factor * 1000 for t in target_returns]\n\n# Left plot: Efficient frontier.\nfig.add_trace(\n    go.Scatter(\n        x=std_dev_dollars,\n        y=return_dollars,\n        mode=\"lines+markers\",\n        marker=dict(size=6, color=sharpe_ratios, colorscale=\"Viridis\", showscale=False),\n        line=dict(color=\"steelblue\", width=2),\n        hovertemplate=\"Std Dev: $%{x:.0f}<br>Return: $%{y:.0f}<extra></extra>\",\n        showlegend=False,\n    ),\n    row=1,\n    col=1,\n)\n\n# Middle plot: Sharpe ratio vs return.\nfig.add_trace(\n    go.Scatter(\n        x=return_dollars,\n        y=sharpe_ratios,\n        mode=\"lines+markers\",\n        marker=dict(size=6, color=sharpe_ratios, colorscale=\"Viridis\", showscale=False),\n        line=dict(color=\"steelblue\", width=2),\n        hovertemplate=\"Return: $%{x:.0f}<br>Sharpe: %{y:.2f}<extra></extra>\",\n        showlegend=False,\n    ),\n    row=1,\n    col=2,\n)\n\n# Right plot: Asset allocation.\nfor i, (name, color) in enumerate(zip(stock_names, colors)):\n    fig.add_trace(\n        go.Bar(\n            x=target_dollars,\n            y=[float(w) * 1000 for w in all_weights[:, i]],\n            name=name,\n            marker_color=color,\n            hovertemplate=f\"{name}: $%{{y:.0f}}<extra></extra>\",\n        ),\n        row=1,\n        col=3,\n    )\n\nfig.update_xaxes(title_text=\"Std Dev ($)\", row=1, col=1)\nfig.update_yaxes(title_text=\"Return ($)\", row=1, col=1)\nfig.update_xaxes(title_text=\"Return ($)\", row=1, col=2)\nfig.update_yaxes(title_text=\"Sharpe Ratio\", row=1, col=2)\nfig.update_xaxes(title_text=\"Target Return ($)\", row=1, col=3)\nfig.update_yaxes(title_text=\"Investment ($)\", range=[0, 1050], row=1, col=3)\n\nfig.update_layout(\n    barmode=\"stack\",\n    height=400,\n    margin=dict(t=40, b=40, l=60, r=40),\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, xanchor=\"center\", x=0.83),\n)\nHTML(fig.to_html(full_html=False, include_plotlyjs=\"cdn\"))"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Comparison with constrained approach\n",
    "\n",
    "The manifold and constrained approaches produce the same efficient frontier. The key difference\n",
    "is in how constraints are enforced:\n",
    "\n",
    "| Approach | Budget constraint | No short-selling | Implementation |\n",
    "|----------|------------------|------------------|----------------|\n",
    "| Constrained | Explicit equality constraint | Explicit inequality constraint | Augmented Lagrangian |\n",
    "| Manifold | Built into `retract_fn` | Built into `retract_fn` | Multiplicative retraction |\n",
    "\n",
    "The manifold approach can be advantageous when:\n",
    "- Constraints define a smooth manifold with a simple retraction\n",
    "- You want to avoid the overhead of the Augmented Lagrangian solver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}