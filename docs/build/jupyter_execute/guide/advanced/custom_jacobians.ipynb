{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Custom Jacobians\n",
    "\n",
    "Using analytical Jacobians instead of autodiff for performance-critical costs.\n",
    "\n",
    "Features used:\n",
    "- {func}`@jaxls.Cost.factory <jaxls.Cost.factory>` with `jac_custom_fn` for custom Jacobians\n",
    "- {func}`@jaxls.Cost.factory <jaxls.Cost.factory>` with `jac_custom_with_cache_fn` for cached intermediates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, format=\"<level>{level: <8}</level> | {message}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## When to use custom Jacobians\n",
    "\n",
    "JAX's automatic differentiation is powerful and efficient for most use cases. However, there are situations where providing analytical Jacobians can be beneficial:\n",
    "\n",
    "1. **Known closed-form solutions**: When the Jacobian has a simple analytical form that is faster to compute than autodiff.\n",
    "2. **Numerical stability**: When the analytical form is more numerically stable than the autodiff computation.\n",
    "3. **Reusing intermediates**: When the residual computation produces intermediate values that can be reused for the Jacobian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Problem setup: 2D point fitting\n",
    "\n",
    "We'll demonstrate custom Jacobians with a simple 2D point fitting problem. Given a set of target points, we want to find the optimal location that minimizes the sum of squared distances.\n",
    "\n",
    "For a point $p \\in \\mathbb{R}^2$ and target $t_i \\in \\mathbb{R}^2$, the residual is the Euclidean distance:\n",
    "$$r_i(p) = \\|p - t_i\\|$$\n",
    "\n",
    "The Jacobian of the distance with respect to the point is:\n",
    "$$\\frac{\\partial r_i}{\\partial p} = \\frac{(p - t_i)^T}{\\|p - t_i\\|}$$\n",
    "\n",
    "This is a simple 1x2 row vector (residual dimension 1, tangent dimension 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target points: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define a 2D point variable.\n",
    "class Point2DVar(jaxls.Var[jax.Array], default_factory=lambda: jnp.zeros(2)):\n",
    "    \"\"\"A 2D point variable.\"\"\"\n",
    "\n",
    "\n",
    "# Generate random target points.\n",
    "num_targets = 100\n",
    "key = jax.random.PRNGKey(42)\n",
    "targets = jax.random.normal(key, (num_targets, 2))\n",
    "\n",
    "print(f\"Target points: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Basic usage: `jac_custom_fn`\n",
    "\n",
    "The simplest way to provide a custom Jacobian is via the `jac_custom_fn` parameter. This function takes the same arguments as the residual function and returns a 2D Jacobian matrix.\n",
    "\n",
    "**Important**: The Jacobian shape must be `(residual_dim, sum_of_tangent_dims_of_variables)`. For a single `Point2DVar`, this is `(1, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_jacobian(\n",
    "    vals: jaxls.VarValues,\n",
    "    var: Point2DVar,\n",
    "    target: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Analytical Jacobian of distance residual.\n",
    "\n",
    "    Returns:\n",
    "        Jacobian matrix of shape (1, 2).\n",
    "    \"\"\"\n",
    "    point = vals[var]\n",
    "    diff = point - target\n",
    "    dist = jnp.linalg.norm(diff)\n",
    "    # Jacobian is (p - t)^T / ||p - t||, reshaped to (1, 2).\n",
    "    return (diff / dist).reshape(1, 2)\n",
    "\n",
    "\n",
    "@jaxls.Cost.factory(jac_custom_fn=distance_jacobian)\n",
    "def distance_cost_custom(\n",
    "    vals: jaxls.VarValues,\n",
    "    var: Point2DVar,\n",
    "    target: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Distance residual with custom Jacobian.\"\"\"\n",
    "    point = vals[var]\n",
    "    return jnp.linalg.norm(point - target).reshape(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "For comparison, here's the same cost using autodiff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jaxls.Cost.factory\n",
    "def distance_cost_autodiff(\n",
    "    vals: jaxls.VarValues,\n",
    "    var: Point2DVar,\n",
    "    target: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Distance residual with autodiff Jacobian.\"\"\"\n",
    "    point = vals[var]\n",
    "    return jnp.linalg.norm(point - target).reshape(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## With cache: `jac_custom_with_cache_fn`\n",
    "\n",
    "When computing the residual produces intermediate values that can be reused for the Jacobian, use `jac_custom_with_cache_fn`. The residual function must return a tuple of `(residual, cache)`, and the Jacobian function receives this cache as its second argument.\n",
    "\n",
    "In our distance example, both the residual and Jacobian need `diff = point - target` and `dist = ||diff||`. We can compute these once and cache them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class DistanceCache(NamedTuple):\n",
    "    \"\"\"Cache for distance computation.\"\"\"\n",
    "\n",
    "    diff: jax.Array  # point - target.\n",
    "    dist: jax.Array  # ||diff||.\n",
    "\n",
    "\n",
    "def distance_jacobian_with_cache(\n",
    "    vals: jaxls.VarValues,\n",
    "    cache: DistanceCache,\n",
    "    var: Point2DVar,\n",
    "    target: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Jacobian using cached intermediate values.\n",
    "\n",
    "    Args:\n",
    "        vals: Variable values (not used since we have cache).\n",
    "        cache: Cached diff and dist from residual computation.\n",
    "        var: The point variable.\n",
    "        target: Target point.\n",
    "\n",
    "    Returns:\n",
    "        Jacobian matrix of shape (1, 2).\n",
    "    \"\"\"\n",
    "    # Reuse cached values instead of recomputing.\n",
    "    return (cache.diff / cache.dist).reshape(1, 2)\n",
    "\n",
    "\n",
    "@jaxls.Cost.factory(jac_custom_with_cache_fn=distance_jacobian_with_cache)\n",
    "def distance_cost_cached(\n",
    "    vals: jaxls.VarValues,\n",
    "    var: Point2DVar,\n",
    "    target: jax.Array,\n",
    ") -> tuple[jax.Array, DistanceCache]:\n",
    "    \"\"\"Distance residual that caches intermediates for Jacobian.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (residual, cache) - the cache is passed to the Jacobian function.\n",
    "    \"\"\"\n",
    "    point = vals[var]\n",
    "    diff = point - target\n",
    "    dist = jnp.linalg.norm(diff)\n",
    "    cache = DistanceCache(diff=diff, dist=dist)\n",
    "    return dist.reshape(1), cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Jacobian shape requirements\n",
    "\n",
    "The Jacobian must have shape `(residual_dim, sum_of_tangent_dims_of_variables)`. Let's verify our Jacobians have the correct shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian shape: (1, 2)\n",
      "Expected: (residual_dim=1, tangent_dim=2)\n",
      "\n",
      "Custom Jacobian:\n",
      "[[0.4472136 0.8944272]]\n",
      "Autodiff Jacobian:\n",
      "[[0.4472136 0.8944272]]\n",
      "Match: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Jacobian:\n",
      "[[0.4472136 0.8944272]]\n",
      "Autodiff Jacobian:\n",
      "[[0.4472136 0.8944272]]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Create a test point and target.\n",
    "test_var = Point2DVar(id=0)\n",
    "test_point = jnp.array([1.0, 2.0])\n",
    "test_target = jnp.array([0.0, 0.0])\n",
    "test_vals = jaxls.VarValues.make([test_var.with_value(test_point)])\n",
    "\n",
    "# Check Jacobian shape from custom function.\n",
    "jac = distance_jacobian(test_vals, test_var, test_target)\n",
    "print(f\"Jacobian shape: {jac.shape}\")\n",
    "print(\"Expected: (residual_dim=1, tangent_dim=2)\")\n",
    "\n",
    "# Verify against autodiff.\n",
    "jac_autodiff = jax.jacrev(lambda p: jnp.linalg.norm(p - test_target).reshape(1))(\n",
    "    test_point\n",
    ")\n",
    "print(f\"\\nCustom Jacobian:\\n{jac}\")\n",
    "print(f\"Autodiff Jacobian:\\n{jac_autodiff}\")\n",
    "print(f\"Match: {jnp.allclose(jac, jac_autodiff)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Solving the optimization problem\n",
    "\n",
    "Let's verify all three approaches produce the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n",
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_autodiff\n",
      "Autodiff: point = [0.104448, 0.063558]\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n",
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_custom\n",
      "Custom : point = [0.104459, 0.063558]\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n",
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_cached\n",
      "Cached : point = [0.104459, 0.063558]\n",
      "\n",
      "Target mean: [-0.024155, 0.041008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_autodiff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodiff: point = [0.104448, 0.063558]\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom : point = [0.104459, 0.063558]\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_cached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached : point = [0.104459, 0.063558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target mean: [-0.024155, 0.041008]\n"
     ]
    }
   ],
   "source": [
    "def solve_with_cost_factory(cost_factory, name: str) -> jax.Array:\n",
    "    \"\"\"Solve the point fitting problem with a given cost factory.\"\"\"\n",
    "    var = Point2DVar(id=0)\n",
    "\n",
    "    # Create batched costs for all targets.\n",
    "    costs = [\n",
    "        cost_factory(\n",
    "            Point2DVar(id=jnp.zeros(num_targets, dtype=jnp.int32)),\n",
    "            targets,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Initial guess away from the solution.\n",
    "    initial_vals = jaxls.VarValues.make([var.with_value(jnp.array([5.0, 5.0]))])\n",
    "\n",
    "    # Solve.\n",
    "    problem = jaxls.LeastSquaresProblem(costs, [var]).analyze()\n",
    "    solution = problem.solve(initial_vals, verbose=False)\n",
    "\n",
    "    result = solution[var]\n",
    "    print(f\"{name}: point = [{result[0]:.6f}, {result[1]:.6f}]\")\n",
    "    return result\n",
    "\n",
    "\n",
    "result_autodiff = solve_with_cost_factory(distance_cost_autodiff, \"Autodiff\")\n",
    "result_custom = solve_with_cost_factory(distance_cost_custom, \"Custom \")\n",
    "result_cached = solve_with_cost_factory(distance_cost_cached, \"Cached \")\n",
    "\n",
    "# The optimal point should be close to the mean of targets.\n",
    "# (for sum of squared distances, the minimum is at the geometric median,\n",
    "# which is close to the mean for normally distributed points)\n",
    "print(f\"\\nTarget mean: [{targets[:, 0].mean():.6f}, {targets[:, 1].mean():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Performance comparison\n",
    "\n",
    "Let's compare the timing of autodiff vs custom Jacobians. Note that for this simple example, the difference may be small or even favor autodiff due to JAX's optimizations. Custom Jacobians are most beneficial for:\n",
    "\n",
    "- Complex functions where the analytical Jacobian is simpler\n",
    "- Cases where intermediate values can be heavily reused\n",
    "- Very high-dimensional problems where autodiff has significant overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking solve times...\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n",
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_autodiff\n",
      "Autodiff      : 0.165 ms (min of 20 runs)\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n",
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_custom\n",
      "Custom Jacobian: 0.162 ms (min of 20 runs)\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n",
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_cached\n",
      "With Cache     : 0.165 ms (min of 20 runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_autodiff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodiff      : 0.165 ms (min of 20 runs)\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Jacobian: 0.162 ms (min of 20 runs)\n",
      "\u001b[1mINFO    \u001b[0m | Building optimization problem with 100 terms and 1 variables: 100 costs, 0 eq_zero, 0 leq_zero, 0 geq_zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | Vectorizing group with 100 costs, 1 variables each: distance_cost_cached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Cache     : 0.165 ms (min of 20 runs)\n"
     ]
    }
   ],
   "source": [
    "def benchmark_solver(cost_factory, name: str, num_runs: int = 20) -> float:\n",
    "    \"\"\"Benchmark a solver configuration.\n",
    "\n",
    "    Returns:\n",
    "        Minimum time per solve in milliseconds.\n",
    "    \"\"\"\n",
    "    var = Point2DVar(id=0)\n",
    "\n",
    "    costs = [\n",
    "        cost_factory(\n",
    "            Point2DVar(id=jnp.zeros(num_targets, dtype=jnp.int32)),\n",
    "            targets,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    initial_vals = jaxls.VarValues.make([var.with_value(jnp.array([5.0, 5.0]))])\n",
    "    problem = jaxls.LeastSquaresProblem(costs, [var]).analyze()\n",
    "\n",
    "    # Warmup (JIT compilation).\n",
    "    solution = problem.solve(initial_vals, verbose=False)\n",
    "    jax.block_until_ready(solution[var])\n",
    "\n",
    "    # Timed runs.\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        start = time.perf_counter()\n",
    "        solution = problem.solve(initial_vals, verbose=False)\n",
    "        jax.block_until_ready(solution[var])  # Important: wait for async execution!\n",
    "        times.append(time.perf_counter() - start)\n",
    "\n",
    "    min_time = min(times) * 1000  # Convert to ms.\n",
    "    print(f\"{name}: {min_time:.3f} ms (min of {num_runs} runs)\")\n",
    "    return min_time\n",
    "\n",
    "\n",
    "print(\"Benchmarking solve times...\\n\")\n",
    "t_autodiff = benchmark_solver(distance_cost_autodiff, \"Autodiff      \")\n",
    "t_custom = benchmark_solver(distance_cost_custom, \"Custom Jacobian\")\n",
    "t_cached = benchmark_solver(distance_cost_cached, \"With Cache     \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Multiple variables\n",
    "\n",
    "When a cost involves multiple variables, the Jacobian concatenates their tangent dimensions in the order they appear as arguments. For example, a cost with two `Point2DVar` variables would have a Jacobian of shape `(residual_dim, 4)` (2 + 2 tangent dims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-variable Jacobian shape: (1, 4)\n",
      "Jacobian:\n",
      "[[ 0.70710677 -0.70710677 -0.70710677  0.70710677]]\n"
     ]
    }
   ],
   "source": [
    "def two_point_jacobian(\n",
    "    vals: jaxls.VarValues,\n",
    "    var_a: Point2DVar,\n",
    "    var_b: Point2DVar,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Jacobian for distance between two points.\n",
    "\n",
    "    The residual is ||p_a - p_b||, and the Jacobian has shape (1, 4)\n",
    "    with columns [d/dp_a, d/dp_b].\n",
    "    \"\"\"\n",
    "    p_a = vals[var_a]\n",
    "    p_b = vals[var_b]\n",
    "    diff = p_a - p_b\n",
    "    dist = jnp.linalg.norm(diff)\n",
    "    # d/dp_a = (p_a - p_b) / ||p_a - p_b||.\n",
    "    # d/dp_b = -(p_a - p_b) / ||p_a - p_b||.\n",
    "    jac_a = diff / dist\n",
    "    jac_b = -diff / dist\n",
    "    return jnp.concatenate([jac_a, jac_b]).reshape(1, 4)\n",
    "\n",
    "\n",
    "@jaxls.Cost.factory(jac_custom_fn=two_point_jacobian)\n",
    "def two_point_distance(\n",
    "    vals: jaxls.VarValues,\n",
    "    var_a: Point2DVar,\n",
    "    var_b: Point2DVar,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Distance between two points.\"\"\"\n",
    "    return jnp.linalg.norm(vals[var_a] - vals[var_b]).reshape(1)\n",
    "\n",
    "\n",
    "# Verify the multi-variable Jacobian shape.\n",
    "var_a = Point2DVar(id=0)\n",
    "var_b = Point2DVar(id=1)\n",
    "test_vals = jaxls.VarValues.make(\n",
    "    [\n",
    "        var_a.with_value(jnp.array([1.0, 0.0])),\n",
    "        var_b.with_value(jnp.array([0.0, 1.0])),\n",
    "    ]\n",
    ")\n",
    "\n",
    "jac = two_point_jacobian(test_vals, var_a, var_b)\n",
    "print(f\"Two-variable Jacobian shape: {jac.shape}\")\n",
    "print(f\"Jacobian:\\n{jac}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Important notes\n",
    "\n",
    "1. Correctness: Custom Jacobians bypass autodiff entirely. If your Jacobian is incorrect, the solver may converge to the wrong solution or fail to converge. Always verify against autodiff during development.\n",
    "\n",
    "2. Shape requirements: The Jacobian must be a 2D array with shape `(residual_dim, total_tangent_dim)`. The tangent dimensions are concatenated in the order variables appear as arguments.\n",
    "\n",
    "3. Caching: Use `jac_custom_with_cache_fn` when the residual computation produces expensive intermediate values that the Jacobian can reuse. This avoids duplicate computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}